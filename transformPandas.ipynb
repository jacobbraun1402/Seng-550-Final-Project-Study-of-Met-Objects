{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import subprocess\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "import pyspark.pandas as ps\n",
    "import numpy as np\n",
    "import pyspark.ml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/18 17:50:27 WARN Utils: Your hostname, Jacobs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.104 instead (on interface en0)\n",
      "24/12/18 17:50:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/18 17:50:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"TransformPandas\").config(\"spark.ui.port\", '4050').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = subprocess.check_output('ls extractedDataset | grep \".*.csv\"', shell=True, text=True).removesuffix('\\n')\n",
    "path = os.getcwd() + \"/extractedDataset/\" + fileName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/pandas/utils.py:1016: PandasAPIOnSparkAdviceWarning: If `index_col` is not specified for `read_csv`, the default index is attached which can cause additional overhead.\n",
      "  warnings.warn(message, PandasAPIOnSparkAdviceWarning)\n"
     ]
    }
   ],
   "source": [
    "df = ps.read_csv(path, index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessionYear</th>\n",
       "      <th>artistGender</th>\n",
       "      <th>artistNationality</th>\n",
       "      <th>culture</th>\n",
       "      <th>department</th>\n",
       "      <th>isHighlight</th>\n",
       "      <th>isTimelineWork</th>\n",
       "      <th>objectEndDate</th>\n",
       "      <th>objectID</th>\n",
       "      <th>objectName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>None</td>\n",
       "      <td>The American Wing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1907</td>\n",
       "      <td>14</td>\n",
       "      <td>Coin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>The American Wing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1814</td>\n",
       "      <td>108</td>\n",
       "      <td>Andiron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The American Wing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1890</td>\n",
       "      <td>366</td>\n",
       "      <td>Basket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>The American Wing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1870</td>\n",
       "      <td>540</td>\n",
       "      <td>Bitters bottle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1937</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>The American Wing</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1800</td>\n",
       "      <td>653</td>\n",
       "      <td>Bottle fragment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accessionYear artistGender artistNationality   culture         department  isHighlight  isTimelineWork  objectEndDate  objectID       objectName\n",
       "0          1979         None          American      None  The American Wing        False           False           1907        14             Coin\n",
       "1          1989         None          American  American  The American Wing        False           False           1814       108          Andiron\n",
       "2          1946         None              None      None  The American Wing        False           False           1890       366           Basket\n",
       "3          1946         None              None  American  The American Wing        False           False           1870       540   Bitters bottle\n",
       "4          1937         None              None  American  The American Wing        False           False           1800       653  Bottle fragment"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>objectEndDate</th>\n",
       "      <th>objectID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5048.000000</td>\n",
       "      <td>5048.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1411.472464</td>\n",
       "      <td>403327.783479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>982.326369</td>\n",
       "      <td>246533.239840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5000.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1596.000000</td>\n",
       "      <td>217951.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1843.000000</td>\n",
       "      <td>383850.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1909.000000</td>\n",
       "      <td>591846.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2038.000000</td>\n",
       "      <td>920333.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       objectEndDate       objectID\n",
       "count    5048.000000    5048.000000\n",
       "mean     1411.472464  403327.783479\n",
       "std       982.326369  246533.239840\n",
       "min     -5000.000000      14.000000\n",
       "25%      1596.000000  217951.000000\n",
       "50%      1843.000000  383850.000000\n",
       "75%      1909.000000  591846.000000\n",
       "max      2038.000000  920333.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genderColumn(df):\n",
    "    #change nulls to male, just makes it easier to detect if the gender is not female when doing the mapping\n",
    "    df['artistGender'] = df['artistGender'].fillna(value='male')\n",
    "    df['isFemale'] = df['artistGender'].map(lambda x: 0 if x=='male' else 1)\n",
    "    df = df.drop(columns=['artistGender'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDepartmentDummies(df: ps.DataFrame):\n",
    "    dummies = ps.get_dummies(df['department'], prefix=\"department\")\n",
    "    df = df.drop(columns=['department'])\n",
    "    df = ps.concat([df, dummies], axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that applies all of the transformations at once\n",
    "def transformDataset(df):\n",
    "    # in the database, they only store a value in the gender field if the artist is female\n",
    "    # otherwise it is null\n",
    "    # if there are multiple artists attributed to an object, the gender of each artist is shown, separated by a '|'\n",
    "    # I'm going to simplify this a bit by just having this column equal to 1 if there is at least 1 female artist attributed\n",
    "    df = genderColumn(df)\n",
    "    # change the department column to a series of dummy variables\n",
    "    # since there are a small number of distinct departments (X)\n",
    "    df = makeDepartmentDummies(df)\n",
    "    # change isHighlight and isTimelineWork to integers\n",
    "    df['isTimelineWork'] = df['isTimelineWork'].map(lambda x: int(x))\n",
    "    df['isHighlight'] = df['isHighlight'].map(lambda x: int(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/18 17:51:05 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accessionYear</th>\n",
       "      <th>artistNationality</th>\n",
       "      <th>culture</th>\n",
       "      <th>isHighlight</th>\n",
       "      <th>isTimelineWork</th>\n",
       "      <th>objectEndDate</th>\n",
       "      <th>objectID</th>\n",
       "      <th>objectName</th>\n",
       "      <th>isFemale</th>\n",
       "      <th>department_Ancient Near Eastern Art</th>\n",
       "      <th>department_Arms and Armor</th>\n",
       "      <th>department_Asian Art</th>\n",
       "      <th>department_Costume Institute</th>\n",
       "      <th>department_Drawings and Prints</th>\n",
       "      <th>department_Egyptian Art</th>\n",
       "      <th>department_European Paintings</th>\n",
       "      <th>department_European Sculpture and Decorative Arts</th>\n",
       "      <th>department_Greek and Roman Art</th>\n",
       "      <th>department_Islamic Art</th>\n",
       "      <th>department_Medieval Art</th>\n",
       "      <th>department_Modern and Contemporary Art</th>\n",
       "      <th>department_Musical Instruments</th>\n",
       "      <th>department_Photographs</th>\n",
       "      <th>department_Robert Lehman Collection</th>\n",
       "      <th>department_The American Wing</th>\n",
       "      <th>department_The Cloisters</th>\n",
       "      <th>department_The Libraries</th>\n",
       "      <th>department_The Michael C. Rockefeller Wing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>American</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1907</td>\n",
       "      <td>14</td>\n",
       "      <td>Coin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1989</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1814</td>\n",
       "      <td>108</td>\n",
       "      <td>Andiron</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1946</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1890</td>\n",
       "      <td>366</td>\n",
       "      <td>Basket</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1946</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1870</td>\n",
       "      <td>540</td>\n",
       "      <td>Bitters bottle</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1937</td>\n",
       "      <td>None</td>\n",
       "      <td>American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>653</td>\n",
       "      <td>Bottle fragment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1946</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1880</td>\n",
       "      <td>779</td>\n",
       "      <td>Bowl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1910</td>\n",
       "      <td>None</td>\n",
       "      <td>Chinese, for American market</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1790</td>\n",
       "      <td>856</td>\n",
       "      <td>Bowl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1910</td>\n",
       "      <td>None</td>\n",
       "      <td>Chinese, for American market</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1790</td>\n",
       "      <td>867</td>\n",
       "      <td>Bowl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1917</td>\n",
       "      <td>None</td>\n",
       "      <td>Mexican</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1845</td>\n",
       "      <td>895</td>\n",
       "      <td>Cup</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1883</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1800</td>\n",
       "      <td>906</td>\n",
       "      <td>Box</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accessionYear artistNationality                       culture  isHighlight  isTimelineWork  objectEndDate  objectID       objectName  isFemale  department_Ancient Near Eastern Art  department_Arms and Armor  department_Asian Art  department_Costume Institute  department_Drawings and Prints  department_Egyptian Art  department_European Paintings  department_European Sculpture and Decorative Arts  department_Greek and Roman Art  department_Islamic Art  department_Medieval Art  department_Modern and Contemporary Art  department_Musical Instruments  department_Photographs  department_Robert Lehman Collection  department_The American Wing  department_The Cloisters  department_The Libraries  department_The Michael C. Rockefeller Wing\n",
       "0          1979          American                          None            0               0           1907        14             Coin         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "1          1989          American                      American            0               0           1814       108          Andiron         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "2          1946              None                          None            0               0           1890       366           Basket         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "3          1946              None                      American            0               0           1870       540   Bitters bottle         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "4          1937              None                      American            0               0           1800       653  Bottle fragment         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "5          1946          American                      American            0               0           1880       779             Bowl         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "6          1910              None  Chinese, for American market            0               0           1790       856             Bowl         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "7          1910              None  Chinese, for American market            0               0           1790       867             Bowl         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "8          1917              None                       Mexican            0               0           1845       895              Cup         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0\n",
       "9          1883              None                          None            0               0           1800       906              Box         0                                    0                          0                     0                             0                               0                        0                              0                                                  0                               0                       0                        0                                       0                               0                       0                                    0                             1                         0                         0                                           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_df = transformDataset(df)\n",
    "mod_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "PySparkTypeError",
     "evalue": "[CANNOT_INFER_SCHEMA_FOR_TYPE] Can not infer schema for type: `str`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VectorAssembler\n\u001b[0;32m----> 2\u001b[0m sparkDF2 \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# columns = mod_df.columns.to_list()\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# features = columns.remove('isHighlight')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# print(features)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# vec = VectorAssembler(inputCols=features, outputCol='isHighlight')\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# vec_x = vec.transform(mod_df)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/session.py:1443\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_pandas \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;66;03m# Create a DataFrame from pandas DataFrame.\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m(SparkSession, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mcreateDataFrame(  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m         data, schema, samplingRatio, verifySchema\n\u001b[1;32m   1442\u001b[0m     )\n\u001b[0;32m-> 1443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamplingRatio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverifySchema\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1445\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/session.py:1485\u001b[0m, in \u001b[0;36mSparkSession._create_dataframe\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m   1483\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_createFromRDD(data\u001b[38;5;241m.\u001b[39mmap(prepare), schema, samplingRatio)\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1485\u001b[0m     rdd, struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_createFromLocal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mSerDeUtil\u001b[38;5;241m.\u001b[39mtoJavaArray(rdd\u001b[38;5;241m.\u001b[39m_to_java_object_rdd())\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/session.py:1093\u001b[0m, in \u001b[0;36mSparkSession._createFromLocal\u001b[0;34m(self, data, schema)\u001b[0m\n\u001b[1;32m   1090\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m-> 1093\u001b[0m     struct \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inferSchemaFromList\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1094\u001b[0m     converter \u001b[38;5;241m=\u001b[39m _create_converter(struct)\n\u001b[1;32m   1095\u001b[0m     tupled_data: Iterable[Tuple] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(converter, data)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/session.py:955\u001b[0m, in \u001b[0;36mSparkSession._inferSchemaFromList\u001b[0;34m(self, data, names)\u001b[0m\n\u001b[1;32m    953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n\u001b[1;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[0;32m--> 955\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_merge_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_nulltype(schema):\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m    970\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_DETERMINE_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    971\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    972\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/session.py:958\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    953\u001b[0m infer_array_from_first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jconf\u001b[38;5;241m.\u001b[39mlegacyInferArrayTypeFromFirstElement()\n\u001b[1;32m    954\u001b[0m prefer_timestamp_ntz \u001b[38;5;241m=\u001b[39m is_timestamp_ntz_preferred()\n\u001b[1;32m    955\u001b[0m schema \u001b[38;5;241m=\u001b[39m reduce(\n\u001b[1;32m    956\u001b[0m     _merge_type,\n\u001b[1;32m    957\u001b[0m     (\n\u001b[0;32m--> 958\u001b[0m         \u001b[43m_infer_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dict_as_struct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_array_from_first_element\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer_timestamp_ntz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    966\u001b[0m     ),\n\u001b[1;32m    967\u001b[0m )\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_nulltype(schema):\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkValueError(\n\u001b[1;32m    970\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_DETERMINE_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    971\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m    972\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pyspark/sql/types.py:1684\u001b[0m, in \u001b[0;36m_infer_schema\u001b[0;34m(row, names, infer_dict_as_struct, infer_array_from_first_element, prefer_timestamp_ntz)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(row\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1684\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   1685\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANNOT_INFER_SCHEMA_FOR_TYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1686\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(row)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[1;32m   1687\u001b[0m     )\n\u001b[1;32m   1689\u001b[0m fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m items:\n",
      "\u001b[0;31mPySparkTypeError\u001b[0m: [CANNOT_INFER_SCHEMA_FOR_TYPE] Can not infer schema for type: `str`."
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "sparkDF2 = spark.createDataFrame(mod_df)\n",
    "# columns = mod_df.columns.to_list()\n",
    "# features = columns.remove('isHighlight')\n",
    "# print(features)\n",
    "# vec = VectorAssembler(inputCols=features, outputCol='isHighlight')\n",
    "# vec_x = vec.transform(mod_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
